{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "210d2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp # python 3.7 로 해야.... 하루종일 걸려서 발견...\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime \n",
    "import pickle \n",
    "\n",
    "from pypfopt import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99031594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labelling import XYGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399d9583",
   "metadata": {},
   "source": [
    "# Dataloading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897a8511",
   "metadata": {},
   "source": [
    "## X loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8172632",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pd_setting(dataframe):\n",
    "    dataframe.rename(columns = {'Unnamed: 0':'Date'}, inplace = True)\n",
    "    dataframe['Date'] = dataframe.Date.apply(lambda x : datetime.datetime.strptime(x, '%Y-%m-%d') )\n",
    "    dataframe = dataframe.set_index(['Date'])\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecbccbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df = pd_setting(pd.read_csv(\"./data/features/price_df.csv\"))\n",
    "mu_df = pd_setting(pd.read_csv(\"./data/features/mu_df.csv\"))\n",
    "sigma_df = pd_setting(pd.read_csv(\"./data/features/sigma_df.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac99647",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_date = price_df.index\n",
    "dff_col_name = list(price_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7bfd28",
   "metadata": {},
   "source": [
    "## Y loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3151eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv(\"./data/df_XY.csv\")\n",
    "dff.rename(columns = {'Unnamed: 0':'Date'}, inplace = True)\n",
    "dff['Date'] = dff.Date.apply(lambda x : datetime.datetime.strptime(x, '%Y-%m-%d') )\n",
    "dff = dff.set_index(['Date'])\n",
    "\n",
    "dfy = dff.loc[feat_date]\n",
    "# extracting Y columns\n",
    "Y_col = [x for x in dfy.columns if x[-2:]=='_Y']\n",
    "dfy = dfy[Y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc2a587",
   "metadata": {},
   "source": [
    "# XY Generation\n",
    "- df_target : dfy\n",
    "- df_intput : price_df, mu_df, sigma_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4b48d0",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45dfd90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29f83a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_col_name = price_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a6a1d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8184, 27)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70d0626c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7931, 27)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cb8f208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price normalization \n",
    "# z_scaler = StandardScaler()\n",
    "# z_scaler.fit(price_df)\n",
    "# price_df_z = z_scaler.transform(price_df)\n",
    "# price_df_z = pd.DataFrame(price_df_z, columns = dff_col_name, index = feat_date)\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaler.fit(price_df)\n",
    "price_df_mm = min_max_scaler.transform(price_df)\n",
    "price_df_mm = pd.DataFrame(price_df_mm, columns = dff_col_name, index = feat_date)\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaler.fit(mu_df)\n",
    "mu_df_mm = min_max_scaler.transform(mu_df)\n",
    "mu_df_mm = pd.DataFrame(mu_df_mm, columns = dff_col_name, index = feat_date)\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaler.fit(sigma_df)\n",
    "sigma_df_mm = min_max_scaler.transform(sigma_df)\n",
    "sigma_df_mm = pd.DataFrame(sigma_df_mm, columns = dff_col_name, index = feat_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdb93cd",
   "metadata": {},
   "source": [
    "# Dataset Generation & Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0feb07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_past_seq = 120  \n",
    "tr_past_seq = 252\n",
    "rf = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c72f9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading generator\n",
    "generator = XYGeneration(dfy, tr_past_seq, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b580eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y labelling \n",
    "Y = generator.Y_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a643a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c87d13",
   "metadata": {},
   "source": [
    "### X concatenation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6333a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_p, x_index = generator.X_generation(price_df_mm, in_past_seq)\n",
    "x_m, _ = generator.X_generation(mu_df_mm, in_past_seq)\n",
    "x_s, _ = generator.X_generation(sigma_df_mm, in_past_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4105b90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "543cef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(len(x_index)):\n",
    "    x_p_arr = np.expand_dims(x_p[i], -1)\n",
    "    x_m_arr = np.expand_dims(x_m[i], -1)\n",
    "    x_s_arr = np.expand_dims(x_s[i], -1)\n",
    "    \n",
    "    X_arr = np.concatenate([x_p_arr, x_m_arr, x_s_arr], axis = -1)\n",
    "    \n",
    "    X.append(X_arr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0855fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4f1af4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa9445e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376f92bd",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d38f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0a9d6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 27, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b0ab956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 27, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "322e6128",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(X)\n",
    "num_train = round(len(X)*0.7)\n",
    "\n",
    "num_val = round(num_train*0.2)\n",
    "num_train = num_train - num_val\n",
    "num_test = num_samples - num_train\n",
    "\n",
    "\n",
    "\n",
    "num_nodes = X[0].shape[1]\n",
    "feat_dim = X[0].shape[-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_train, y_train = X[:num_train], Y[:num_train]\n",
    "x_val, y_val = X[num_train : num_train+num_val], Y[num_train : num_train+num_val]\n",
    "x_test , y_test = X[num_train+num_val : ], Y[num_train+num_val : ]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aad94473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 120, 27, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cf7ea3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 120, 27, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_val).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72ca8d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 120, 27, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10ec8414",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = ([(torch.from_numpy(x).float(),torch.from_numpy(y).float()) for x,y in zip(x_train, y_train)])\n",
    "val_iter = ([(torch.from_numpy(x).float(),torch.from_numpy(y).float()) for x,y in zip(x_val, y_val)])\n",
    "test_iter = ([(torch.from_numpy(x).float(),torch.from_numpy(y).float()) for x,y in zip(x_test, y_test)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a112bdc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 27, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter[-1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3635f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 27, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_iter[-1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "107a3154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False],\n",
       "         ...,\n",
       "         [False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False]],\n",
       "\n",
       "        [[False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False],\n",
       "         ...,\n",
       "         [False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False]],\n",
       "\n",
       "        [[False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False],\n",
       "         ...,\n",
       "         [False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False],\n",
       "         ...,\n",
       "         [False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False]],\n",
       "\n",
       "        [[False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False],\n",
       "         ...,\n",
       "         [False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False]],\n",
       "\n",
       "        [[False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False],\n",
       "         ...,\n",
       "         [False, False, False],\n",
       "         [False, False, False],\n",
       "         [False, False, False]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter[-1][0] == val_iter[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7342bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = DataLoader(train_iter, batch_size=12, shuffle=True, drop_last = True)\n",
    "valid_dataloader = DataLoader(val_iter, batch_size=12, shuffle=True, drop_last = True)\n",
    "test_dataloader = DataLoader(test_iter, batch_size=12, shuffle=True, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02d6a37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fd596572c50>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be5b9cc",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26120ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim = 1)\n",
    "input = torch.randn(2,3,1,1)\n",
    "o = m(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85c260a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "\n",
    "\n",
    "class nconv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(nconv,self).__init__()\n",
    "\n",
    "    def forward(self,x, A):\n",
    "        x = torch.einsum('ncvl,vw->ncwl',(x,A))\n",
    "        return x.contiguous()\n",
    "\n",
    "class linear(nn.Module):\n",
    "    def __init__(self,c_in,c_out):\n",
    "        super(linear,self).__init__()\n",
    "        self.mlp = torch.nn.Conv2d(c_in, c_out, kernel_size=(1, 1), padding=(0,0), stride=(1,1), bias=True) # \n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class gcn(nn.Module):\n",
    "    def __init__(self,c_in,c_out,dropout,support_len=3,order=2):\n",
    "        super(gcn,self).__init__()\n",
    "        self.nconv = nconv()\n",
    "        c_in = (order*support_len+1)*c_in\n",
    "        self.mlp = linear(c_in,c_out)\n",
    "        self.dropout = dropout\n",
    "        self.order = order\n",
    "\n",
    "    def forward(self,x,support):\n",
    "        out = [x]\n",
    "        for a in support:\n",
    "            x1 = self.nconv(x,a)\n",
    "            out.append(x1)\n",
    "            for k in range(2, self.order + 1):\n",
    "#                 print (\"K\")\n",
    "#                 print (k)\n",
    "                \n",
    "                \n",
    "#                 print (x1.shape)\n",
    "#                 print (a.shape)\n",
    "                \n",
    "                x2 = self.nconv(x1,a)\n",
    "                out.append(x2)\n",
    "                x1 = x2\n",
    "        \n",
    "        h = torch.cat(out,dim=1)\n",
    "        h = self.mlp(h)\n",
    "        h = F.dropout(h, self.dropout, training=self.training)\n",
    "        return h\n",
    "    \n",
    "###############################################################################################################################################\n",
    "###############################################################################################################################################\n",
    "class gwnet(nn.Module):\n",
    "    def __init__(self, device, num_nodes, dropout=0.3, supports=None, gcn_bool=True, addaptadj=True, aptinit=None, \n",
    "                 in_dim=3, out_dim=1, out_dim2 = 9, residual_channels=32,dilation_channels=32,skip_channels=256,\n",
    "                 end_channels=512,kernel_size=2,blocks=4,layers=2):\n",
    "        super(gwnet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.blocks = blocks\n",
    "        self.layers = layers\n",
    "        self.gcn_bool = gcn_bool\n",
    "        self.addaptadj = addaptadj\n",
    "\n",
    "        self.filter_convs = nn.ModuleList()\n",
    "        self.gate_convs = nn.ModuleList()\n",
    "        self.residual_convs = nn.ModuleList()\n",
    "        self.skip_convs = nn.ModuleList()\n",
    "        self.bn = nn.ModuleList()\n",
    "        self.gconv = nn.ModuleList()\n",
    "\n",
    "        self.start_conv = nn.Conv2d(in_channels=in_dim,\n",
    "                                    out_channels=residual_channels,\n",
    "                                    kernel_size=(1,1))\n",
    "        self.supports = supports\n",
    "\n",
    "        receptive_field = 1\n",
    "\n",
    "        self.supports_len = 0\n",
    "        if supports is not None:\n",
    "            self.supports_len += len(supports)\n",
    "\n",
    "        if gcn_bool and addaptadj:\n",
    "            if aptinit is None:\n",
    "                if supports is None:\n",
    "                    self.supports = []\n",
    "                self.nodevec1 = nn.Parameter(torch.randn(num_nodes, 10).to(device), requires_grad=True).to(device)\n",
    "                self.nodevec2 = nn.Parameter(torch.randn(10, num_nodes).to(device), requires_grad=True).to(device)\n",
    "                self.supports_len +=1\n",
    "            else:\n",
    "                if supports is None:\n",
    "                    self.supports = []\n",
    "                m, p, n = torch.svd(aptinit)\n",
    "                initemb1 = torch.mm(m[:, :10], torch.diag(p[:10] ** 0.5))\n",
    "                initemb2 = torch.mm(torch.diag(p[:10] ** 0.5), n[:, :10].t())\n",
    "                self.nodevec1 = nn.Parameter(initemb1, requires_grad=True).to(device)\n",
    "                self.nodevec2 = nn.Parameter(initemb2, requires_grad=True).to(device)\n",
    "                self.supports_len += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for b in range(blocks):\n",
    "            additional_scope = kernel_size - 1\n",
    "            new_dilation = 1\n",
    "            for i in range(layers):\n",
    "                # dilated convolutions\n",
    "                self.filter_convs.append(nn.Conv2d(in_channels=residual_channels,\n",
    "                                                   out_channels=dilation_channels,\n",
    "                                                   kernel_size=(1,kernel_size),dilation=new_dilation))\n",
    "\n",
    "                self.gate_convs.append(nn.Conv1d(in_channels=residual_channels,\n",
    "                                                 out_channels=dilation_channels,\n",
    "                                                 kernel_size=(1, kernel_size), dilation=new_dilation))\n",
    "\n",
    "                # 1x1 convolution for residual connection\n",
    "                self.residual_convs.append(nn.Conv1d(in_channels=dilation_channels,\n",
    "                                                     out_channels=residual_channels,\n",
    "                                                     kernel_size=(1, 1)))\n",
    "\n",
    "                # 1x1 convolution for skip connection\n",
    "                self.skip_convs.append(nn.Conv1d(in_channels=dilation_channels,\n",
    "                                                 out_channels=skip_channels,\n",
    "                                                 kernel_size=(1, 1)))\n",
    "                self.bn.append(nn.BatchNorm2d(residual_channels))\n",
    "                new_dilation *=2\n",
    "                \n",
    "                \n",
    "#                 print ('dilation: ', new_dilation)\n",
    "                \n",
    "                \n",
    "                receptive_field += additional_scope\n",
    "                additional_scope *= 2\n",
    "                if self.gcn_bool:\n",
    "                    self.gconv.append(gcn(dilation_channels,residual_channels,dropout,support_len=self.supports_len))\n",
    "\n",
    "\n",
    "\n",
    "        self.end_conv_1 = nn.Conv2d(in_channels=skip_channels,\n",
    "                                  out_channels=end_channels,\n",
    "                                  kernel_size=(1,1),\n",
    "                                  bias=True)\n",
    "\n",
    "        self.end_conv_2 = nn.Conv2d(in_channels=end_channels,\n",
    "                                    out_channels=out_dim,\n",
    "                                    kernel_size=(1,1),\n",
    "                                    bias=True)\n",
    "        \n",
    "        self.end_conv_3 = nn.Conv2d(in_channels = num_nodes,\n",
    "                                   out_channels = out_dim2, \n",
    "                                   kernel_size = (1,1), \n",
    "                                   bias = True)\n",
    "        \n",
    "        self.soft_max = nn.Softmax(dim = 1)\n",
    "        \n",
    "        self.receptive_field = receptive_field\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        in_len = input.size(3)\n",
    "        if in_len<self.receptive_field:\n",
    "            x = nn.functional.pad(input,(self.receptive_field-in_len,0,0,0))\n",
    "        else:\n",
    "            x = input\n",
    "        x = self.start_conv(x)\n",
    "        skip = 0\n",
    "\n",
    "        # calculate the current adaptive adj matrix once per iteration\n",
    "        new_supports = None\n",
    "        if self.gcn_bool and self.addaptadj and self.supports is not None:\n",
    "            adp = F.softmax(F.relu(torch.mm(self.nodevec1, self.nodevec2)), dim=1)\n",
    "            new_supports = self.supports + [adp]\n",
    "\n",
    "        # WaveNet layers\n",
    "        for i in range(self.blocks * self.layers):\n",
    "#             print ('layers: ', self.blocks * self.layers)\n",
    "\n",
    "            #            |----------------------------------------|     *residual*\n",
    "            #            |                                        |\n",
    "            #            |    |-- conv -- tanh --|                |\n",
    "            # -> dilate -|----|                  * ----|-- 1x1 -- + -->\t*input*\n",
    "            #                 |-- conv -- sigm --|     |\n",
    "            #                                         1x1\n",
    "            #                                          |\n",
    "            # ---------------------------------------> + ------------->\t*skip*\n",
    "\n",
    "            #(dilation, init_dilation) = self.dilations[i]\n",
    "\n",
    "            #residual = dilation_func(x, dilation, init_dilation, i)\n",
    "            residual = x\n",
    "            # dilated convolution\n",
    "            filter = self.filter_convs[i](residual)\n",
    "            filter = torch.tanh(filter)\n",
    "            gate = self.gate_convs[i](residual)\n",
    "            gate = torch.sigmoid(gate)\n",
    "            x = filter * gate\n",
    "\n",
    "            # parametrized skip connection\n",
    "\n",
    "            s = x\n",
    "            s = self.skip_convs[i](s)\n",
    "            try:\n",
    "                skip = skip[:, :, :,  -s.size(3):]\n",
    "            except:\n",
    "                skip = 0\n",
    "            skip = s + skip\n",
    "\n",
    "\n",
    "            if self.gcn_bool and self.supports is not None:\n",
    "                if self.addaptadj:\n",
    "                    x = self.gconv[i](x, new_supports)\n",
    "                else:\n",
    "                    x = self.gconv[i](x,self.supports)\n",
    "            else:\n",
    "                x = self.residual_convs[i](x)\n",
    "\n",
    "            x = x + residual[:, :, :, -x.size(3):]\n",
    "\n",
    "\n",
    "            x = self.bn[i](x)\n",
    "\n",
    "        x = F.relu(skip)\n",
    "        x = F.relu(self.end_conv_1(x))\n",
    "        x = self.end_conv_2(x) # [batch, dim, num_nodes, seq]\n",
    "        # [12,1,27,1]\n",
    "        \n",
    "        \n",
    "        x = x.transpose(2,1) # [12,27,1,1] [batch, num node, 1, 1]\n",
    "        \n",
    "        x = self.end_conv_3(x).transpose(3,1) \n",
    "        # [12,27,1,1] --> [12,9,1,1] --> [12,1,1,9] \n",
    "        \n",
    "        x = self.soft_max(x) \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3e89a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "num_nodes = 27\n",
    "dropout = 0.3\n",
    "learning_rate = 0.001\n",
    "wdecay = 0.0001\n",
    "\n",
    "gcn_bool = True\n",
    "addaptadj=True\n",
    "aptinit=None\n",
    "in_dim = 3\n",
    "out_dim = 1\n",
    "out_dim2 = 9\n",
    "nhid = 32\n",
    "\n",
    "kernel_size = 20\n",
    "\n",
    "residual_channels=nhid \n",
    "dilation_channels=nhid\n",
    "skip_channels=nhid * 8\n",
    "end_channels=nhid * 16\n",
    "\n",
    "num_block = 4\n",
    "num_layer = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8579c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model \n",
    "model = gwnet(device,num_nodes,dropout,supports=None,gcn_bool=gcn_bool,addaptadj=addaptadj,aptinit=aptinit,in_dim=in_dim,out_dim=out_dim, out_dim2=out_dim2,residual_channels=nhid,dilation_channels=nhid,skip_channels=nhid * 8,end_channels=nhid*16,kernel_size=20,blocks=num_block,layers=num_layer)\n",
    "model.to(device) # model loading\n",
    "\n",
    "criterion = torch.nn.L1Loss() # MAE \n",
    "criterion2 = torch.nn.KLDivLoss() # cross En\n",
    "\n",
    "# criterion = torch.nn.L1Loss() # MAE \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = wdecay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "231553bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.KLDivLoss()\n",
    "\n",
    "out = torch.randn(12,9)\n",
    "pred = torch.randn(12,1,9)\n",
    "\n",
    "# loss(out,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4fbb1a",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bdf589ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50| tarin loss : -0.29407477378845215, valid loss : -0.29407477378845215\n",
      "Epoch 100| tarin loss : -0.29407477378845215, valid loss : -0.29407477378845215\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 100\n",
    "\n",
    "loss_train = []\n",
    "loss_valid = []\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()\n",
    "\n",
    "    epoch_train_loss = [] # loss average for one epoch\n",
    "    epoch_valid_loss = []\n",
    "##### training \n",
    "    for data in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_X, train_Y = data\n",
    "        train_X = train_X.transpose(3,1)\n",
    "        train_X = nn.functional.pad(train_X,(kernel_size-1,0,0,0))\n",
    "\n",
    "        train_X = torch.Tensor(train_X).to(device)\n",
    "        train_Y = torch.Tensor(train_Y).to(device)\n",
    "        train_Y = train_Y.unsqueeze(1)\n",
    "#         print ('X : ', train_X.size())\n",
    "#         print ('Y : ', train_Y.size())\n",
    "        train_out = model(train_X) #  [12,1,1,9] --> [12,1,9]\n",
    "#         print ('out : ', train_out.size())\n",
    "        train_out = train_out.squeeze()\n",
    "        train_out = train_out.unsqueeze(1)\n",
    "#         print('out: ',train_out.size())\n",
    "\n",
    "#         loss = criterion(train_out,train_Y)\n",
    "        loss = criterion2(train_out,train_Y)\n",
    "        \n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss.append(loss.item())\n",
    "\n",
    "    loss_train.append(np.mean(epoch_train_loss))\n",
    "    \n",
    "##### validation \n",
    "    for data in valid_dataloader:\n",
    "        valid_X, valid_Y = data\n",
    "        valid_X = valid_X.transpose(3,1)\n",
    "        valid_X = nn.functional.pad(valid_X, (kernel_size-1,0,0,0))\n",
    "        \n",
    "        valid_X = torch.Tensor(valid_X).to(device)\n",
    "        valid_Y = torch.Tensor(valid_Y).to(device)\n",
    "        valid_Y = valid_Y.unsqueeze(1)\n",
    "        \n",
    "        valid_out = model(valid_X)\n",
    "        valid_out = valid_out.squeeze()\n",
    "        valid_out = valid_out.unsqueeze(1)\n",
    "        \n",
    "#         loss = criterion(valid_out, valid_Y)\n",
    "        loss = criterion2(valid_out, valid_Y)\n",
    "        \n",
    "        epoch_valid_loss.append(loss.item())\n",
    "    loss_valid.append(np.mean(epoch_valid_loss))\n",
    "        \n",
    "    \n",
    "    if epoch%50 == 0:\n",
    "        print (\"Epoch {}| tarin loss : {}, valid loss : {}\".format(epoch,np.mean(epoch_train_loss), np.mean(epoch_valid_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c2cbc55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:1', grad_fn=<SelectBackward>)\n",
      "tensor(0.2500, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "i = 6\n",
    "print (valid_out[i][0][1])\n",
    "print (valid_Y[i][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b275634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd58ca46f90>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(loss_train, label = 'train')\n",
    "plt.plot(loss_valid, label = 'valid')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a87a4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QRFT",
   "language": "python",
   "name": "qrft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
